{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac4bd66f-3003-4361-bdf0-3edfabd6aa93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import rasterio\n",
    "import os\n",
    "from rasterio.plot import show\n",
    "from rasterio import features\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import io\n",
    "from rasterio.transform import from_origin\n",
    "from rasterio.plot import show\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "import mapclassify as mc\n",
    "import numpy as np\n",
    "from rasterio.transform import from_origin\n",
    "import rasterio\n",
    "from joblib import Parallel, delayed\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7a2a57",
   "metadata": {},
   "source": [
    "## Overview: AHP-based suitability modelling\n",
    "\n",
    "This section applies the **Analytic Hierarchy Process (AHP)** to identify suitable areas for placing in-stream wetlands based on expert knowledge and environmental criteria.\n",
    "\n",
    "AHP is a multi-criteria decision-making method that:\n",
    "- Structures the decision problem hierarchically (goal → criteria → alternatives)\n",
    "- Uses pairwise comparisons to assign weights to each criterion\n",
    "- Aggregates weighted raster layers to produce a final suitability map\n",
    "\n",
    "The same input variables used in the RF model (TWI, slope, SOC, clay, flow accumulation) are used here, but combined through a rule-based approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8e566e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Calculating weights for AHP\n",
    "\n",
    "In this step, we compute the **criterion weights** using the Analytic Hierarchy Process (AHP), based on a **pairwise comparison matrix**.\n",
    "\n",
    "**Steps:**\n",
    "1. **Load the reciprocal matrix** from a CSV file or define it directly in the notebook. The matrix should express the relative importance of each criterion using Saaty's 1–9 scale.\n",
    "2. **Compute the principal eigenvector** of the matrix, which gives the relative weights of each criterion.\n",
    "3. **Normalise the eigenvector** to ensure the weights sum to 1.\n",
    "4. **Calculate the Consistency Index (CI)** and **Consistency Ratio (CR)** to check whether the comparisons are consistent.  \n",
    "   - A CR value below **0.10** indicates an acceptable level of consistency.\n",
    "5. **Display the final weights**, which will be used to weight the raster layers during map calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dfc21ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slope</th>\n",
       "      <th>flow_acc</th>\n",
       "      <th>twi</th>\n",
       "      <th>soc</th>\n",
       "      <th>clay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>slope</th>\n",
       "      <td>1.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flow_acc</th>\n",
       "      <td>0.11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>twi</th>\n",
       "      <td>0.50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.14</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soc</th>\n",
       "      <td>2.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>7.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clay</th>\n",
       "      <td>0.20</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.14</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          slope  flow_acc   twi   soc  clay\n",
       "slope      1.00       9.0  2.00  0.50  5.00\n",
       "flow_acc   0.11       1.0  0.20  0.11  0.33\n",
       "twi        0.50       5.0  1.00  0.14  3.00\n",
       "soc        2.00       9.0  7.00  1.00  7.00\n",
       "clay       0.20       3.0  0.33  0.14  1.00"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load your reciprocals matrix as a dataframe\n",
    "# you can make it as a csv or using a dict in here, just make sure the result looks like this example\n",
    "# (but do not use THIS example because I just made up the numbers)\n",
    "# it doesn't matter which \"direction\" you calculate relative importance in, just make sure you are consistent\n",
    "reciprocals = pd.read_csv('criteria.csv', index_col=0) #Pairwise Comparison Matrix\n",
    "reciprocals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9108d15",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slope</th>\n",
       "      <th>flow_acc</th>\n",
       "      <th>twi</th>\n",
       "      <th>soc</th>\n",
       "      <th>clay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Weight</th>\n",
       "      <td>0.26</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        slope  flow_acc   twi   soc  clay\n",
       "Weight   0.26      0.03  0.13  0.51  0.06"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.05149613021365207"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CR=0.04, Level of consistance is aceptable\n"
     ]
    }
   ],
   "source": [
    "# get principal eigenvector and eigenvalue\n",
    "eigvals, eigvecs = np.linalg.eig(reciprocals)\n",
    "principal_eigvec = eigvecs[:,0]\n",
    "principal_eigval = eigvals[0] # AKA lambda max\n",
    "\n",
    "# normalize principal eigenvector to get priority vector\n",
    "# all complex components are zero so we can use np.real to get the real part\n",
    "priority_vec = np.real(principal_eigvec / principal_eigvec.sum())\n",
    "\n",
    "#these will be our weights\n",
    "weights = pd.DataFrame({column: round(priority, 2) for column, priority in zip(reciprocals.index, priority_vec)}, index=['Weight'])\n",
    "display(weights)\n",
    "\n",
    "# calculate consistency index\n",
    "# this should be less than 0.10\n",
    "ci = (np.real(principal_eigval) - len(reciprocals)) / (len(reciprocals) - 1)\n",
    "display(ci)\n",
    "n=len(reciprocals)\n",
    "ri=1.41 #ramdom index for n classes\n",
    "cr=round((ci/ri),2)\n",
    "if cr<=0.1:\n",
    "    print('CR='+str(cr)+', Level of consistance is aceptable')\n",
    "else:\n",
    "    print('CR='+str(cr)+', Level of consistance is NOT aceptable')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8621a7-a9d0-43b3-b699-62a61d0f8c5a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Working with raster variables as NumPy arrays and exploring basic statistics\n",
    "\n",
    "we load each environmental variable (e.g. slope,tw,flow acc, soc, clay) as a **NumPy array** from its corresponding raster file.\n",
    "\n",
    "In this step:\n",
    "- The raster is read using `rasterio`, and the first band is converted to a NumPy array.\n",
    "- We check for the presence of **NaN values**, which represent missing data.\n",
    "- Basic descriptive statistics (help to understand the data distribution) are calculated:\n",
    "  - **Minimum and maximum values**\n",
    "  - **25th, 50th (median), and 75th percentiles**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090e7f59",
   "metadata": {},
   "source": [
    "You must update the raster filename according to the **data source** (local or global) and **resolution** (10 m or 50 m) you are using.\n",
    "\n",
    "Refer to the table below to select the correct raster file:\n",
    "\n",
    "| Variable     | Local 10 m                | Local 50 m                | Global 10 m               | Global 50 m               |\n",
    "|--------------|---------------------------|---------------------------|---------------------------|---------------------------|\n",
    "| **TWI**      | `twi_10m_a.tif`           | `twi_50m_a.tif`           | `twi_10m_GEE_a.tif`       | `twi_50m_GEE_a.tif`       |\n",
    "| **Slope**    | `slope_10m_a.tif`         | `slope_50m_a.tif`         | `slope_10m_GEE_a.tif`     | `slope_50m_GEE_a.tif`     |\n",
    "| **Clay**     | `clay_10m_a.tif`          | `clay_50m_a.tif`          | `clay_10m_GEE_a.tif`      | `clay_50m_GEE_a.tif`      |\n",
    "| **SOC**      | `soc_10m_a.tif`           | `soc_50m_a.tif`           | `soc_10m_GEE_a.tif`       | `soc_50m_GEE_a.tif`       |\n",
    "| **Flow Acc.**| `flow_acc_10m_a.tif`      | `flow_acc_50m_a.tif`      | `flow_acc_10m_GEE_a.tif`  | `flow_acc_50m_GEE_a.tif`  |\n",
    "\n",
    "Repeat this step for all variables you plan to include in your AHP model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f1de20-c55a-4845-a444-958602526044",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "###  Slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1687e67c-5d66-4f25-9e8c-4c066c856e9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#raster to numpy array\n",
    "data_directory = 'data'\n",
    "filename='slope_50m_a.tif'\n",
    "input_raster =os.path.join(data_directory, filename)\n",
    "# open raster with rasterio\n",
    "with rasterio.open(input_raster) as src:\n",
    "    # read the data with NumPy matrix \n",
    "    slope_array = src.read(1)  # read the first band as NumPy matrix \n",
    "    src.close()\n",
    "    #print(\"Number of bands:\", src.count)\n",
    "    print(\"NumPy array dimensions:\", slope_array.shape)\n",
    "    print(\"min value:\", np.nanmin(slope_array))\n",
    "    print(\"max value:\", np.nanmax(slope_array))\n",
    "\n",
    "# nan values \n",
    "has_nans = np.isnan(slope_array).any()\n",
    "print(has_nans)  \n",
    "\n",
    "# Flatten the array and remove NaN values for calculations\n",
    "slope_array_flat = slope_array.flatten()\n",
    "slope_array_flat_no_nan = slope_array_flat[~np.isnan(slope_array_flat)]\n",
    "\n",
    "# Calculate percentiles\n",
    "print(\"25th Percentile (Slope):\", np.percentile(slope_array_flat_no_nan, 25))\n",
    "print(\"50th Percentile (Median) (Slope):\", np.percentile(slope_array_flat_no_nan, 50))\n",
    "print(\"75th Percentile (Slope):\", np.percentile(slope_array_flat_no_nan, 75))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a58edd8-ef24-4032-a225-7ddb94dd072b",
   "metadata": {},
   "source": [
    "#### Selection criteria and suitability rating for in-stream wetland placement – *Slope*\n",
    "\n",
    "The table below defines suitability classes for locating in-stream wetlands, based on slope values. Lower slopes are preferred, as they favour water retention and reduce flow velocity, making them more appropriate for wetland functioning within stream systems.\n",
    "\n",
    "| **Suitability Class**        | **Slope Range (degrees)** |\n",
    "|-----------------------------|:--------------------------:|\n",
    "| 1 – No suitability           | *x* > 6                    |\n",
    "| 2 – Marginally suitable      | 3 < *x* ≤ 6                |\n",
    "| 3 – Moderately suitable      | 2 < *x* ≤ 3                |\n",
    "| 4 – Highly suitable          | *x* ≤ 2                    |\n",
    "\n",
    "These thresholds will be used to **reclassify the slope raster** into suitability scores prior to AHP overlay.\n",
    "\n",
    "**Note**: These threshold values are based on **local 50 m resolution data**. If you are using data from a different source or resolution (e.g. global 10 m), you should explore your raster statistics and adjust the ranges accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bf3a63-7bf9-4ad4-9236-4583e6586d24",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy array dimensions: (5138, 7403)\n",
      "Classification array min value: 1.0\n",
      "Classification array max value: 4.0\n"
     ]
    }
   ],
   "source": [
    "#Selection criteria and suitability rating \n",
    "tem1 = np.where(slope_array <= 2, 4, 0)\n",
    "tem2 = np.where((slope_array > 2) & (slope_array <= 3), 3, 0)\n",
    "tem3 = np.where((slope_array > 3) & (slope_array <= 6), 2, 0)\n",
    "tem4 = np.where(slope_array > 6, 1, 0)\n",
    "\n",
    "slope_array=tem1+tem2+tem3+tem4\n",
    "\n",
    "#Replace 0s with NaN\n",
    "slope_array = np.where(slope_array == 0, np.nan, slope_array)\n",
    "\n",
    "print(\"NumPy array dimensions:\", slope_array.shape)\n",
    "print(\"Classification array min value:\", np.nanmin(slope_array))\n",
    "print(\"Classification array max value:\", np.nanmax(slope_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0977eb6-0d0b-40e1-9bce-e60a407b7864",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### numpy array to raster in the same location of the pixel \n",
    "src = rasterio.open(input_raster)\n",
    "transform = src.transform\n",
    "slope_array = slope_array.astype(np.float32) \n",
    "output_raster_path = 'reclassified_slope_50m.tif' \n",
    "\n",
    "#new raster\n",
    "with rasterio.open(output_raster_path, 'w', driver='GTiff',\n",
    "                   height=slope_array.shape[0], width=slope_array.shape[1],\n",
    "                   count=1, dtype='float32',  \n",
    "                   crs=\"EPSG:3301\", transform=transform) as dst:\n",
    "    # NumPy array to raster \n",
    "    dst.write(slope_array, 1)\n",
    "    dst.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dea51c3-b8ea-45de-9543-1e94b5859460",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Flow accumulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75502750-eeaa-4f97-9de9-8b2bd11c365b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy array dimensions: (5138, 7403)\n",
      "min value: -3195.4011\n",
      "max value: 55781.043\n",
      "Negative values have been replaced with NaN.\n",
      "Min value (excluding NaN): 0.0043320963\n",
      "Max value (excluding NaN): 55781.043\n",
      "25th Percentile: 0.00458943285048008\n",
      "50th Percentile (Median): 0.008123337291181087\n",
      "75th Percentile: 0.029373185709118843\n"
     ]
    }
   ],
   "source": [
    "#raster to numpy array\n",
    "data_directory = 'data'\n",
    "filename='flow_acc_50m_a.tif'\n",
    "input_raster =os.path.join(data_directory, filename)\n",
    "# open raster with rasterio\n",
    "with rasterio.open(input_raster) as src:\n",
    "    # read the data with NumPy matrix \n",
    "    flow_acc_array = src.read(1)  # read the first band as NumPy matrix \n",
    "    print(\"NumPy array dimensions:\", flow_acc_array.shape)\n",
    "    print(\"min value:\", np.nanmin(flow_acc_array))\n",
    "    print(\"max value:\", np.nanmax(flow_acc_array))\n",
    "    \n",
    "    # Assume negative values are NoData and replace with NaN\n",
    "    flow_acc_array = np.where(flow_acc_array < 0, np.nan, flow_acc_array)\n",
    "    print(\"Negative values have been replaced with NaN.\")\n",
    "    # Print the min and max values\n",
    "    print(\"Min value (excluding NaN):\", np.nanmin(flow_acc_array))\n",
    "    print(\"Max value (excluding NaN):\", np.nanmax(flow_acc_array))\n",
    "\n",
    "# Flatten the array and remove NaN values for calculations\n",
    "flow_acc_array_flat = flow_acc_array.flatten()\n",
    "flow_acc_array_flat_no_nan = flow_acc_array_flat[~np.isnan(flow_acc_array_flat)]\n",
    "\n",
    "# Print percentiles\n",
    "print(\"25th Percentile:\",  np.percentile(flow_acc_array_flat_no_nan, 25))\n",
    "print(\"50th Percentile (Median):\", np.percentile(flow_acc_array_flat_no_nan, 50))\n",
    "print(\"75th Percentile:\", np.percentile(flow_acc_array_flat_no_nan, 75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719b22fa-0d22-4c56-b4ff-60b2cbc169ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##NATURAL BREAK ANALYSIS\n",
    "# Flatten the array as Jenks Natural Breaks works on a 1D array\n",
    "flow_acc_array_1d = flow_acc_array.flatten()\n",
    "flow_acc_array_no_nan = flow_acc_array_1d[~np.isnan(flow_acc_array_1d)]\n",
    "# Calculate the natural breaks for the data\n",
    "breaks = mc.NaturalBreaks(flow_acc_array_no_nan, k=4)\n",
    "print(f\"Natural breaks (Class limits): {breaks.bins}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d72b1c-f721-4060-9273-31199b02123c",
   "metadata": {},
   "source": [
    "#### Selection criteria and suitability rating for in-stream wetland placement – *Flow Accumulation*\n",
    "\n",
    "The table defines suitability classes based on **flow accumulation**, which indicates the amount of upstream area contributing surface flow to a given location. Higher flow accumulation areas are more likely to intercept significant runoff\n",
    "\n",
    "| **Suitability Class**        | **Flow Accumulation (x)** |\n",
    "|-----------------------------|:--------------------------:|\n",
    "| 1 – No suitability           | *x* < 5                    |\n",
    "| 2 – Marginally suitable      | 5 ≤ *x* < 100              |\n",
    "| 3 – Moderately suitable      | 100 ≤ *x* < 1000           |\n",
    "| 4 – Highly suitable          | *x* ≥ 1000                 |\n",
    "\n",
    "These thresholds are used to reclassify the flow accumulation raster into discrete suitability scores for integration into the AHP model.\n",
    "\n",
    "**Note**: These threshold values are based on **local 50 m resolution data**. If you are using data from a different source or resolution (e.g. global 10 m), you should explore your raster statistics and adjust the ranges accordingly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "995929ac-75fc-49cb-b5df-46f7214d5dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy array dimensions: (5138, 7403)\n",
      "Classification array min value: 1.0\n",
      "Classification array max value: 4.0\n"
     ]
    }
   ],
   "source": [
    "#Selection criteria and suitability rating \n",
    "tem1 = np.where(flow_acc_array >= 1000, 4, 0)\n",
    "tem2 = np.where((flow_acc_array >= 100) & (flow_acc_array < 1000), 3, 0)\n",
    "tem3 = np.where((flow_acc_array >= 5) & (flow_acc_array < 100), 2, 0)\n",
    "tem4 = np.where(flow_acc_array < 5, 1, 0)\n",
    "\n",
    "flow_acc_array=tem1+tem2+tem3+tem4\n",
    "\n",
    "# Replace 0s with NaN\n",
    "flow_acc_array = np.where(flow_acc_array == 0, np.nan, flow_acc_array)\n",
    "\n",
    "print(\"NumPy array dimensions:\", flow_acc_array.shape)\n",
    "print(\"Classification array min value:\", np.nanmin(flow_acc_array))\n",
    "print(\"Classification array max value:\", np.nanmax(flow_acc_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b4e7f42b-29fa-47ab-a2db-0287c8a5da46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##### numpy array to raster  \n",
    "src = rasterio.open(input_raster)\n",
    "transform = src.transform\n",
    "flow_acc_array = flow_acc_array.astype(np.float32)\n",
    "output_raster_path = 'reclassified_flow_acc_50m.tif'  \n",
    "#Create a new raster using rasterio with float32 data type\n",
    "with rasterio.open(output_raster_path, 'w', driver='GTiff',\n",
    "                   height=flow_acc_array.shape[0], width=flow_acc_array.shape[1],\n",
    "                   count=1, dtype='float32',  # Ensure the dtype is set to float32\n",
    "                   crs=\"EPSG:3301\", transform=transform) as dst:\n",
    "    # Write the NumPy array to the new raster\n",
    "    dst.write(flow_acc_array, 1)\n",
    "    dst.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fa1d43-52ae-4fe0-b1ee-c1b6f9de993f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Clay content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17bab73-f778-4cd8-8ae7-f5b920dd04c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy array dimensions: (5138, 7403)\n",
      "min value: 5.0\n",
      "max value: 70.0\n"
     ]
    }
   ],
   "source": [
    "#raster to numpy array\n",
    "data_directory = 'data'\n",
    "filename= 'clay_50m_a.tif'\n",
    "input_raster =os.path.join(data_directory, filename)\n",
    "# open raster with rasterio\n",
    "with rasterio.open(input_raster) as src:\n",
    "    # read the data with NumPy matrix \n",
    "    clay_array = src.read(1)  # read the first band as NumPy matrix \n",
    "    print(\"NumPy array dimensions:\", clay_array.shape)\n",
    "    print(\"min value:\", np.nanmin(clay_array))\n",
    "    print(\"max value:\", np.nanmax(clay_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f6abaf-022e-4f9b-a4bb-ee200b0f0219",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "####NATURAL BREAK ANALYSIS\n",
    "# Flatten the array as Jenks Natural Breaks works on a 1D array\n",
    "clay_array_1d = clay_array.flatten()\n",
    "clay_array_no_nan = clay_array_1d[~np.isnan(clay_array_1d)]\n",
    "# Calculate the natural breaks for the data\n",
    "breaks = mc.NaturalBreaks(clay_array_no_nan, k=4)\n",
    "print(f\"Natural breaks (Class limits): {breaks.bins}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc51dbd1-6c08-45f5-8bbd-7797a426d56f",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Selection criteria and suitability rating for in-stream wetland placement – *Clay Content*\n",
    "\n",
    "Clay content influences soil permeability and water retention. Higher clay percentages are generally more suitable for wetland placement, as they help retain moisture and support hydrological functioning.\n",
    "\n",
    "| **Suitability Class**        | **Clay Content (% by weight)** |\n",
    "|-----------------------------|:-------------------------------:|\n",
    "| 1 – No suitability           | *x* < 11                        |\n",
    "| 2 – Marginally suitable      | 11 ≤ *x* < 27                   |\n",
    "| 3 – Moderately suitable      | 27 ≤ *x* < 38                   |\n",
    "| 4 – Highly suitable          | *x* ≥ 38                        |\n",
    "\n",
    "These thresholds are based on **local 50 m resolution data**. If you are using a different dataset (e.g. global 10 m), explore the raster's distribution and adjust the ranges accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48751a72-fc1f-4854-b37c-1c3c01acf246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy array dimensions: (5138, 7403)\n",
      "Classification array min value: 1.0\n",
      "Classification array max value: 4.0\n"
     ]
    }
   ],
   "source": [
    "#Selection criteria and suitability rating \n",
    "tem1 = np.where(clay_array >=38, 4, 0)\n",
    "tem2 = np.where((clay_array >= 27) & (clay_array < 38), 3, 0)\n",
    "tem3 = np.where((clay_array >= 11) & (clay_array < 27), 2, 0)\n",
    "tem4 = np.where(clay_array < 11, 1, 0)\n",
    "\n",
    "clay_array=tem1+tem2+tem3+tem4\n",
    "\n",
    "# Replace 0s with NaN\n",
    "clay_array = np.where(clay_array == 0, np.nan, clay_array)\n",
    "\n",
    "print(\"NumPy array dimensions:\", clay_array.shape)\n",
    "print(\"Classification array min value:\", np.nanmin(clay_array))\n",
    "print(\"Classification array max value:\", np.nanmax(clay_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1a17b2a0-e460-4a5d-ade8-949dcfb7147d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##### numpy array to raster  \n",
    "from rasterio.transform import from_origin\n",
    "from rasterio.plot import show\n",
    "\n",
    "src = rasterio.open(input_raster)\n",
    "transform = src.transform\n",
    "clay_array = clay_array.astype(np.float32)\n",
    "output_raster_path = 'reclassified_clay_50m.tif'\n",
    "\n",
    "# new raster using rasterio\n",
    "with rasterio.open(output_raster_path, 'w', driver='GTiff',\n",
    "                   height=clay_array.shape[0], width=clay_array.shape[1], \n",
    "                   count=1, dtype='float32',\n",
    "                   crs=\"EPSG:3301\", transform=transform) as dst:\n",
    "#write the NumPy matrix in the new raster\n",
    "    dst.write(clay_array, 1)\n",
    "    dst.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316766ab-d80e-485c-898f-59df806a76b0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Soil organic content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2c5f84-2f15-48e8-8578-c5094e2482d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy array dimensions: (5138, 7403)\n",
      "min value: 0.32780153\n",
      "max value: 35.03709\n"
     ]
    }
   ],
   "source": [
    "data_directory = 'data'\n",
    "filename= 'soc_50m_a.tif'\n",
    "input_raster =os.path.join(data_directory, filename)\n",
    "\n",
    "#open raster with rasterio\n",
    "with rasterio.open(input_raster) as src:\n",
    "    # read the data with NumPy matrix \n",
    "    soc_array = src.read(1)   \n",
    "    # Convert from decigrams per kilogram (dg/kg) to grams per kilogram (g/kg)\n",
    "    soc_array = soc_array # by dividing by 10 (since 1 dg = 0.1 g)\n",
    "    print(\"NumPy array dimensions:\", soc_array.shape)\n",
    "    print(\"min value:\", np.nanmin(soc_array))\n",
    "    print(\"max value:\", np.nanmax(soc_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d8570e-c75a-4717-a774-e17f779a1f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "###NATURAL BREAK ANALYSIS\n",
    "# Flatten the array as Jenks Natural Breaks works on a 1D array\n",
    "soc_array_1d = soc_array.flatten()\n",
    "soc_array_no_nan = soc_array_1d[~np.isnan(soc_array_1d)]\n",
    "# Calculate the natural breaks for the data\n",
    "breaks = mc.NaturalBreaks(soc_array_no_nan, k=4)\n",
    "print(f\"Natural Breaks (Class Limits): {breaks.bins}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42532dd6-f921-4273-9038-fb56041a0ae5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "###STADISTICAL ANALYSIS\n",
    "# Flatten the array and remove NaN values for percentile calculations\n",
    "soc_array_flat = soc_array.flatten()\n",
    "soc_array_flat_no_nan = soc_array_flat[~np.isnan(soc_array_flat)]\n",
    "# Calculate percentiles\n",
    "p25 = np.percentile(soc_array_flat_no_nan, 25)\n",
    "p50 = np.percentile(soc_array_flat_no_nan, 50)\n",
    "p75 = np.percentile(soc_array_flat_no_nan, 75)\n",
    "print(\"25th percentile (%):\", p25)\n",
    "print(\"50th percentile (Median) (%):\", p50)\n",
    "print(\"75th percentile (%):\", p75)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabaa890-8178-4c94-a41e-47f0ba0f0bd0",
   "metadata": {},
   "source": [
    "#### Selection criteria and suitability rating for in-stream wetland placement – *Soil Organic Carbon (SOC)*\n",
    "\n",
    "Soil organic carbon is a key indicator of soil quality and moisture-holding capacity.\n",
    "\n",
    "| **Suitability Class**        | **SOC (% by weight)**     |\n",
    "|-----------------------------|:--------------------------:|\n",
    "| 1 – No suitability           | *x* ≤ 9                    |\n",
    "| 2 – Marginally suitable      | 9 < *x* ≤ 15               |\n",
    "| 3 – Moderately suitable      | 15 < *x* ≤ 27              |\n",
    "| 4 – Highly suitable          | *x* > 27                   |\n",
    "\n",
    "These thresholds are based on **local 50 m resolution data**. If using other data sources or resolutions, check the data range and adjust the values accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5fbab77-65cb-4ab9-b926-58fea23b9f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy array dimensions: (5138, 7403)\n",
      "Classification array min value: 1.0\n",
      "Classification array max value: 4.0\n"
     ]
    }
   ],
   "source": [
    "#Selection criteria and suitability rating \n",
    "tem1 = np.where(soc_array >27, 4, 0)\n",
    "tem2 = np.where((soc_array > 15) & (soc_array <= 27), 3, 0)\n",
    "tem3 = np.where((soc_array > 9) & (soc_array <= 15), 2, 0)\n",
    "tem4 = np.where(soc_array <= 9, 1, 0)\n",
    "\n",
    "soc_array=tem1+tem2+tem3+tem4\n",
    "\n",
    "# Replace 0s with NaN\n",
    "soc_array = np.where(soc_array == 0, np.nan, soc_array)\n",
    "\n",
    "print(\"NumPy array dimensions:\", soc_array.shape)\n",
    "print(\"Classification array min value:\", np.nanmin(soc_array))\n",
    "print(\"Classification array max value:\", np.nanmax(soc_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a8ae0a24-b371-416b-a9a3-9589c8381835",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##### numpy array to raster  \n",
    "src = rasterio.open(input_raster)\n",
    "transform = src.transform\n",
    "soc_array = soc_array.astype(np.float32)\n",
    "\n",
    "output_raster_path = 'reclassified_soc_50m.tif'\n",
    "# new raster using rasterio\n",
    "with rasterio.open(output_raster_path, 'w', driver='GTiff', height=soc_array.shape[0], width=soc_array.shape[1],\n",
    "                   count=1, dtype='float32', crs=\"EPSG:3301\", transform=transform) as dst:\n",
    "#write the NumPy matrix in the new raster\n",
    "    dst.write(soc_array, 1)\n",
    "    dst.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363347b9-e0ea-4fb1-91f8-34fc2dd48d5b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Topographic Wetness Index (TWI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2ffdd2-98d2-4d38-9119-b0cbcd510fd6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones de la matriz NumPy: (5138, 7403)\n",
      "Valor minimo: -99999.0\n",
      "Valor maximo: 16.41423\n",
      "Negative values have been replaced with NaN.\n",
      "Min value (excluding NaN): 2.3344202\n",
      "Max value (excluding NaN): 16.41423\n",
      "25th Percentile: 8.996185302734375\n",
      "50th Percentile (Median): 9.763982772827148\n",
      "75th Percentile: 10.427072525024414\n"
     ]
    }
   ],
   "source": [
    "data_directory = 'data'\n",
    "filename= 'twi_50m_a.tif'\n",
    "input_raster =os.path.join(data_directory, filename)\n",
    "# open raster with rasterio\n",
    "with rasterio.open(input_raster) as src:\n",
    "    # read the data with NumPy matrix \n",
    "    twi_array = src.read(1)  # read the first band as NumPy matrix \n",
    "    print(\"Dimensiones de la matriz NumPy:\", twi_array.shape)\n",
    "    print(\"Valor minimo:\", np.nanmin(twi_array))\n",
    "    print(\"Valor maximo:\", np.nanmax(twi_array))\n",
    "\n",
    "    twi_array = np.where(twi_array < 0, np.nan, twi_array)\n",
    "    print(\"Negative values have been replaced with NaN.\")\n",
    "    \n",
    "    # Print the min and max values\n",
    "    print(\"Min value (excluding NaN):\", np.nanmin(twi_array))\n",
    "    print(\"Max value (excluding NaN):\", np.nanmax(twi_array))\n",
    "\n",
    "# Flatten the array and remove NaN values for calculations\n",
    "twi_array_flat = twi_array.flatten()\n",
    "twi_array_flat_no_nan = twi_array_flat[~np.isnan(twi_array_flat)]\n",
    "\n",
    "# Print percentiles\n",
    "print(\"25th Percentile:\",  np.percentile(twi_array_flat_no_nan, 25))\n",
    "print(\"50th Percentile (Median):\", np.percentile(twi_array_flat_no_nan, 50))\n",
    "print(\"75th Percentile:\", np.percentile(twi_array_flat_no_nan, 75))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbdd652-e4f9-4c57-ba2f-f8819248246e",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Selection criteria and suitability rating for in-stream wetland placement – *Topographic Wetness Index (TWI)*\n",
    "\n",
    "The Topographic Wetness Index (TWI) reflects the potential for water accumulation in the landscape. Higher TWI values typically indicate wetter areas.\n",
    "\n",
    "| **Suitability Class**        | **TWI (x)**                |\n",
    "|-----------------------------|:--------------------------:|\n",
    "| 1 – No suitability           | *x* ≤ 6                    |\n",
    "| 2 – Marginally suitable      | 6 < *x* ≤ 9                |\n",
    "| 3 – Moderately suitable      | 9 < *x* ≤ 11               |\n",
    "| 4 – Highly suitable          | *x* > 11                   |\n",
    "\n",
    "These thresholds are based on **local 50 m resolution data**. For other data sources or resolutions, explore the distribution of TWI values and adjust the ranges accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b210f99d-2714-4139-93ee-d86e86bd300b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy array dimensions: (5138, 7403)\n",
      "Classification array min value: 1.0\n",
      "Classification array max value: 4.0\n"
     ]
    }
   ],
   "source": [
    "#Selection criteria and suitability rating \n",
    "tem1 = np.where(twi_array >11, 4, 0)\n",
    "tem2 = np.where((twi_array > 9) & (twi_array <= 11), 3, 0)\n",
    "tem3 = np.where((twi_array > 6) & (twi_array <= 9), 2, 0)\n",
    "tem4 = np.where(twi_array <= 6, 1, 0)\n",
    "\n",
    "twi_array=tem1+tem2+tem3+tem4\n",
    "\n",
    "# Replace 0s with NaN\n",
    "twi_array = np.where(twi_array == 0, np.nan, twi_array)\n",
    "\n",
    "print(\"NumPy array dimensions:\", twi_array.shape)\n",
    "print(\"Classification array min value:\", np.nanmin(twi_array))\n",
    "print(\"Classification array max value:\", np.nanmax(twi_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "beab3947-8320-4ebb-b444-07cc2cae7450",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##### numpy array to raster  \n",
    "from rasterio.transform import from_origin\n",
    "from rasterio.plot import show\n",
    "\n",
    "src = rasterio.open(input_raster)\n",
    "transform = src.transform\n",
    "twi_array = twi_array.astype(np.float32)\n",
    "\n",
    "output_raster_path = 'reclassified_twi_50m.tif'\n",
    "# new raster \n",
    "with rasterio.open(output_raster_path, 'w', driver='GTiff',\n",
    "                   height=twi_array.shape[0], width=twi_array.shape[1],\n",
    "                   count=1, dtype='float32',\n",
    "                   crs=\"EPSG:3301\", transform=transform) as dst:\n",
    "#write the NumPy matrix in the new raster\n",
    "    dst.write(twi_array, 1)\n",
    "    dst.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157e53a9-a6b0-430c-b603-49327c65f411",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### AHP Suitability Map Creation\n",
    "\n",
    "In this step, we compute the final AHP suitability map by combining the weighted raster layers of all input criteria.\n",
    "\n",
    "Process:\n",
    "- Each reclassified raster array (e.g. slope, TWI, SOC, clay, flow accumulation) is multiplied by its corresponding **AHP weight**.\n",
    "- The weighted layers are then summed to produce a continuous suitability map.\n",
    "- Areas with missing data (NaN values) are preserved in the final output.\n",
    "- The resulting map is saved as a GeoTIFF (`AHP_local_50m_final.tif`) using the spatial reference of one of the input rasters.\n",
    "\n",
    "This example uses **local data at 50 m resolution**. If using a different dataset, be sure to adjust the raster filenames and verify that weights match the variables being used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5644687-652b-4722-8bfd-e12d994a360e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        slope  flow_acc   twi   soc  clay\n",
      "Weight   0.26      0.03  0.13  0.51  0.06\n"
     ]
    }
   ],
   "source": [
    "print(weights) #From AHP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "450fc50c-8c47-4985-a9cf-6afe914bc083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy array dimensions: (5138, 7403)\n",
      "Classification array min value: 0.9899999952316285\n",
      "Classification array max value: 3.959999980926514\n"
     ]
    }
   ],
   "source": [
    "# List of tuples containing the data arrays and their corresponding column names in 'weights'\n",
    "data_items = [\n",
    "    (slope_array, 'slope'),\n",
    "    (flow_acc_array, 'flow_acc'),\n",
    "    (clay_array, 'clay'),\n",
    "    (soc_array, 'soc'),\n",
    "    (twi_array, 'twi'),\n",
    "]\n",
    "\n",
    "# Initialize the suitability map to zero\n",
    "suitability_map = 0\n",
    "\n",
    "# Loop through each item, multiply the data array by its corresponding weight, and add to the suitability map\n",
    "for data_array, weight_key in data_items:\n",
    "    suitability_map += data_array * weights.iloc[0][weight_key]\n",
    "\n",
    "suitability_map[np.isnan(flow_acc_array)]=np.nan\n",
    "\n",
    "# Now suitability_map holds the computed value\n",
    "src = rasterio.open('reclassified_slope_50m.tif')\n",
    "transform = src.transform\n",
    "output_raster_path = 'AHP_local_50m_final.tif'\n",
    "# new raster \n",
    "with rasterio.open(output_raster_path, 'w', driver='GTiff',\n",
    "                   height=suitability_map.shape[0], width=suitability_map.shape[1],\n",
    "                   count=1, dtype=suitability_map.dtype,\n",
    "                   crs=src.crs, transform=transform) as dst:\n",
    "#write the NumPy matrix in the new raster\n",
    "    dst.write(suitability_map, 1)\n",
    "    dst.close()\n",
    "print(\"NumPy array dimensions:\", suitability_map.shape)\n",
    "print(\"Classification array min value:\", np.nanmin(suitability_map))\n",
    "print(\"Classification array max value:\", np.nanmax(suitability_map))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geopython2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
